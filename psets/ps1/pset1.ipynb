{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem Set 1: Text Classification\n",
    "=============\n",
    "\n",
    "In this problem set, you will build a system for automatically classifying reddit comments by subreddit. You will:\n",
    "\n",
    "- Do some basic text processing, tokenizing your input and converting it into a bag-of-words representation\n",
    "- Build a machine learning classifier based on the generative model, using Naive Bayes\n",
    "- Evaluate your classifiers and examine what they have learned\n",
    "- Build a machine learning classifier based on the discriminative model, using Perceptron\n",
    "- Build more stable discriminative classifier, using the averaged perceptron\n",
    "- Build the logistic regression classifier (See instructions within the section)\n",
    "- Implement techniques to improve your classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Setup\n",
    "\n",
    "In order to develop this assignment, you will need the following libraries. Many of these are part of [anaconda](https://www.continuum.io/downloads), so a good starting point would be to install that.\n",
    "\n",
    "- [python 2.7](https://www.python.org/downloads/release/python-2710/) (and not Python 3, although if somebody wants to try that and tell us what goes wrong, that would be appreciated...)\n",
    "- [jupyter notebook](http://jupyter.readthedocs.org/en/latest/install.html)\n",
    "- [scipy](http://www.scipy.org/install.html)\n",
    "- numpy (This will come if you install scipy like above, but if not install separately)\n",
    "- [nltk](http://www.nltk.org/install.html) (tested on NLTK 3.0.4)\n",
    "- [matplotlib](http://matplotlib.org/users/installing.html)\n",
    "- [nosetests](https://nose.readthedocs.org/en/latest/)\n",
    "- [pandas](http://pandas.pydata.org/) Dataframes\n",
    "\n",
    "Here is some help on installing packages in python: https://packaging.python.org/installing/\n",
    "\n",
    "I generally use ```pip --user``` for everything."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About this assignment\n",
    "\n",
    "- This is a Jupyter notebook. You can execute cell blocks by pressing control-enter.\n",
    "- Most of your coding will be in the python source files in the directory ```gtnlplib```.\n",
    "- **To submit this assignment, run the script ```make-submission.sh```, and submit the tarball ```pset1-submission.tgz``` on T-square.**\n",
    "\n",
    "Grading will be mostly based on automated unit testing.\n",
    "\n",
    "- The directory ```tests``` contains unit tests that are very similar to the tests that will be used to grade your assignment --- but not the same! \n",
    "- You should run these tests as you work on the assignment to see that you're on the right track. If you pass them in a non-adversarial way (i.e., you didn't write functions that target these tests directly), you will pass the tests that we use for grading. \n",
    "- Parts 1 and 2 are the foundation for the rest of the assignment. Don't even try to work on the later parts of the assignment until your code passes all tests for parts 1 and 2.\n",
    "- The same is largely true within each part: for example, do not move on to deliverable 4.2 until your code passes the test for deliverable 4.1.\n",
    "- You are free to look at the source code of the unit tests -- though most of the relevant code is also here in this notebook. Learn more about running unit tests at http://pythontesting.net/framework/nose/nose-introduction/\n",
    "- You may want to add more tests, but that is completely optional.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Preprocessing\n",
    "\n",
    "Total: 1 point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_tr = pd.read_csv('reddit-train.csv',encoding='utf-8') # read the training data into a data frame\n",
    "df_dv = pd.read_csv('reddit-dev.csv',encoding='utf-8') # read the dev data into a data frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A dataframe is a structured representation of your data. You can preview your dataframes using ```head()```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>science</td>\n",
       "      <td>Why don't you bother instead and respond prope...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>iama</td>\n",
       "      <td>AAIA's ACES is the database standard (http://w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>iama</td>\n",
       "      <td>So many.  I needed to perform a maintenance ru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>worldnews</td>\n",
       "      <td>Ukraine used to be part of Russia in the Sovie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>worldnews</td>\n",
       "      <td>This wiki article goes into how contentious th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subreddit                                               text\n",
       "0    science  Why don't you bother instead and respond prope...\n",
       "1       iama  AAIA's ACES is the database standard (http://w...\n",
       "2       iama  So many.  I needed to perform a maintenance ru...\n",
       "3  worldnews  Ukraine used to be part of Russia in the Sovie...\n",
       "4  worldnews  This wiki article goes into how contentious th..."
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tr.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your first task is to convert the text to a bag-of-words representation. There are three steps:\n",
    "\n",
    "- Break each input into sentences\n",
    "- Break each sentence into word \"tokens\"\n",
    "- Downcase each token, and add it to a Counter\n",
    "\n",
    "You should use NLTK to complete the tokenization step, and collections.Counter for the bag of words representation. For more about NLTK tokenization, see http://www.nltk.org/book/ch03.html\n",
    "\n",
    "**Deliverable 1.1** Complete the function ```gtnlplib.preproc.tokenize_and_downcase```. (0.5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from gtnlplib import preproc\n",
    "reload(preproc); #terminal semicolon suppresses output\n",
    "\n",
    "# when you edit gtnlplib/preproc.py, you will need to reload it into the notebook, using the line above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# this will not work until you implement it\n",
    "y_tr,x_tr = preproc.read_data('reddit-train.csv', #filename\n",
    "                                       'subreddit', #label field\n",
    "                                       preprocessor=preproc.tokenize_and_downcase) #your preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_dv,x_dv = preproc.read_data('reddit-dev.csv', #filename\n",
    "                                       'subreddit', #label field\n",
    "                                       preprocessor=preproc.tokenize_and_downcase) #your preprocessor\n",
    "y_te,x_te = preproc.read_data('reddit-test.csv', #filename\n",
    "                                       'subreddit', #label field\n",
    "                                       preprocessor=preproc.tokenize_and_downcase) #your preprocessor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Each element in the list ```x_tr``` is a counter, which corresponds to a bag of words.\n",
    "- Each element in the list ```y_tr``` is a string, corresponding to a label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIGINAL TEXT:  I saw an article recently stating that there was a link between angiotensin converting enzymes and Alzheimer's. It said that ACE was partially responsible for the break down of the protein fibers and plaques that form in Alzheimer's. To your knowledge, is there any truth to this and if so, is there a correlation between the prevalence of Alzheimer's and the use of ACE inhibitors in the last few decades?\n",
      "\n",
      "Thank you for the work that you do! I am glad there are much smarter people than I working on research for these cognitive issues. \n",
      "\n",
      "\n",
      "EDIT: I'm really sad I missed this AMA. \n",
      "\n",
      "BAG OF WORDS:  Counter({u'the': 6, u'i': 5, u'and': 4, u'there': 4, u'.': 4, u'that': 4, u'alzheimer': 3, u'for': 3, u'of': 3, u\"'s\": 3, u'this': 2, u'is': 2, u'in': 2, u',': 2, u'to': 2, u'between': 2, u'you': 2, u'was': 2, u'a': 2, u'ace': 2, u'responsible': 1, u'few': 1, u'prevalence': 1, u'edit': 1, u'am': 1, u'it': 1, u'an': 1, u'down': 1, u'really': 1, u'ama': 1, u'are': 1, u'research': 1, u'converting': 1, u'protein': 1, u'inhibitors': 1, u'saw': 1, u'your': 1, u'issues': 1, u'if': 1, u'!': 1, u'people': 1, u'use': 1, u'said': 1, u'knowledge': 1, u'angiotensin': 1, u'fibers': 1, u'plaques': 1, u'much': 1, u':': 1, u'?': 1, u'missed': 1, u'do': 1, u'working': 1, u'recently': 1, u'cognitive': 1, u'form': 1, u'any': 1, u'smarter': 1, u'break': 1, u'article': 1, u\"'m\": 1, u'sad': 1, u'than': 1, u'glad': 1, u'partially': 1, u'on': 1, u'last': 1, u'work': 1, u'enzymes': 1, u'so': 1, u'these': 1, u'truth': 1, u'correlation': 1, u'thank': 1, u'link': 1, u'stating': 1, u'decades': 1})\n"
     ]
    }
   ],
   "source": [
    "i = 100\n",
    "print 'ORIGINAL TEXT: ',df_tr.loc[i]['text']\n",
    "print \n",
    "print 'BAG OF WORDS: ',x_tr[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should now be able to pass the first test, ```test_preproc_d1_1```. \n",
    "Try this by running the following code on the command line:\n",
    "\n",
    "```nosetests -v tests/test_pset1_preproc.py```\n",
    "\n",
    "Now let's aggregate these counts, by running the code block below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corpus_counts = preproc.get_corpus_counts(x_tr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This makes it possible to see the top K most common terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'.', 22920),\n",
       " (u'the', 20303),\n",
       " (u',', 19036),\n",
       " (u'to', 13252),\n",
       " (u'and', 11552)]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_counts.most_common(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word count distributions are said to follow [power law](https://en.wikipedia.org/wiki/Power_law) distributions. In practice, this means that a plot of the log-frequency against the log-rank is nearly linear. Let's see if this holds for our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5.3\n"
     ]
    }
   ],
   "source": [
    "# you need matplotlib version 1.4 or above\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "print matplotlib.__version__\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiYAAAGBCAYAAABSP3qNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xdfaa320>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.loglog([val for word,val in corpus_counts.most_common(4000)])\n",
    "plt.xlabel('rank')\n",
    "plt.ylabel('frequency');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Deliverable 1.2** Now let's compute some statistics about the training and dev data.\n",
    "\n",
    "- Print the token/type ratio for the training data.\n",
    "  You will have to implement ```gtnlplib.preproc_metrics.get_token_type_ratio``` (0.1 points)\n",
    "\n",
    "- Print the number of types which appear exactly once in the training data.\n",
    "  You will have to implement ```gtnlplib.preproc_metrics.type_frequency``` (0.1 points)\n",
    "\n",
    "- Print the number of types that appear in the dev data but not the training data (hint: use [sets](https://docs.python.org/2/library/sets.html) for this)\n",
    "  You will have to implement ```gtnlplib.preproc_metrics.unseen_types``` (0.1 points)\n",
    "  \n",
    "(0.3 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gtnlplib.preproc_metrics import get_token_type_ratio,type_frequency,unseen_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19.67109394737792"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_token_type_ratio(corpus_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14134\n",
      "263\n"
     ]
    }
   ],
   "source": [
    "print type_frequency(corpus_counts,1)\n",
    "print type_frequency(corpus_counts,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Words that appear exactly once are called [hapax-legomena](https://en.wikipedia.org/wiki/Hapax_legomenon).\n",
    "\n",
    "Now let's look at the dev data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.0507739212\n"
     ]
    }
   ],
   "source": [
    "y_dv,x_dv = preproc.read_data('reddit-dev.csv', #filename\n",
    "                                       'subreddit', #label field\n",
    "                                       preprocessor=preproc.tokenize_and_downcase) #your preprocessor\n",
    "corpus_counts_dv = preproc.get_corpus_counts(x_dv)\n",
    "print get_token_type_ratio(corpus_counts_dv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's compute the number of word types in the dev data, which do not appear in the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1737"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unseen_types(corpus_counts,corpus_counts_dv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, you can test your code by running ```nosetests -v tests/test_pset1_preproc.py```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Deliverable 1.3** \n",
    "\n",
    "Why do you think the type-token ratio is lower for the dev data as compared to the training data?\n",
    "\n",
    "Yes the dev set is smaller; why does this impact the type-token ratio? (0.2 pts)\n",
    "\n",
    "*Please put your answer in the file gtnlplib/text-answers.md*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pruning the vocabulary\n",
    "\n",
    "Now let's prune the vocabulary to words that have appeared more than ten times. \n",
    "\n",
    "Please run the following two code blocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3600\n",
      "86\n"
     ]
    }
   ],
   "source": [
    "vocab = [word for word,count in corpus_counts.iteritems() if count > 10]\n",
    "print len(vocab)\n",
    "print len(x_tr[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cutoff is chosen mainly for reasons of speed; in the bakeoff, you may want to have a larger vocabulary, assuming your classifiers are fast enough.\n",
    "\n",
    "Run the code below to prune the data to this vocabulary. It will take a minute or two to complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_tr = [{key:val for key,val in x_i.iteritems() if key in vocab} for x_i in x_tr]\n",
    "x_dv = [{key:val for key,val in x_i.iteritems() if key in vocab} for x_i in x_dv]\n",
    "x_te = [{key:val for key,val in x_i.iteritems() if key in vocab} for x_i in x_te]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68\n"
     ]
    }
   ],
   "source": [
    "print len(x_tr[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Linear classification\n",
    "\n",
    "Now you'll implement the linear classification rule, $\\hat{y} = \\text{argmax}_y \\theta^{\\top} f(x,y)$.\n",
    "\n",
    "You will use these functions in all classifiers in this assignment.\n",
    "\n",
    "Total: 1 point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from gtnlplib import clf_base\n",
    "reload(clf_base)\n",
    "\n",
    "from gtnlplib import constants\n",
    "reload(constants);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Deliverable 2.1** \n",
    "\n",
    "Recall from class and the reading that the feature function vector $f(x,y)$ can be viewed as a dict, in which the values are counts, and the keys are tuples $(y,x_j)$, where $y$ is a label and $x_j$ is a base feature.\n",
    "\n",
    "Implement the function ```make_feature_vector``` in ```clf_base.py```. Desired output is shown below:\n",
    "\n",
    "Note that you must also include the offset feature, ```gtnlplib.constants.OFFSET```.\n",
    "\n",
    "(0.2 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'gtnlplib.clf_base' from 'gtnlplib\\clf_base.pyc'>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(clf_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fv = clf_base.make_feature_vector({'test':1,'case':2},'iama')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{('iama', '**OFFSET**'): 1, ('iama', 'case'): 2, ('iama', 'test'): 1}\n"
     ]
    }
   ],
   "source": [
    "print fv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compute the entire set of labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_tr' is not defined",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-97b4d153a965>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_tr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#figure out all possible labels\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'y_tr' is not defined"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "labels = set(y_tr) #figure out all possible labels\n",
    "print labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Deliverable 2.2**\n",
    "\n",
    "Now implement the prediction rule, $\\hat{y} = \\text{argmax}_y \\theta^{\\top} f(x,y)$.\n",
    "\n",
    "Specifically, implement the function ```predict``` in ```clf_base.py```. The output should be:\n",
    "\n",
    "- A predicted label\n",
    "- The scores of all labels\n",
    "\n",
    "This function will be called **a lot**, so try to make it fast. You don't need to do anything crazy, but avoid making your code do silly extra work.\n",
    "\n",
    "(0.4 points)\n",
    "\n",
    "You can test this function using these simple hand-crafted weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict,Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# weight vectors must be defaultdicts\n",
    "theta_hand = defaultdict(float,\n",
    "                         {('worldnews','worldnews'):1.,\n",
    "                          ('worldnews','news'):.5,\n",
    "                          ('worldnews','world'):.5,\n",
    "                          ('science','science'):1.,\n",
    "                          ('askreddit','askreddit'):1.,\n",
    "                          ('askreddit','ask'):0.5,\n",
    "                          ('iama','iama'):1,\n",
    "                          ('todayilearned','til'):1.,\n",
    "                          ('todayilearned','todayilearned'):1.,\n",
    "                          ('iama',constants.OFFSET):0.1\n",
    "                         })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(u'science',\n",
       " {u'askreddit': 0.0,\n",
       "  u'iama': 0.1,\n",
       "  u'science': 5.0,\n",
       "  u'todayilearned': 0.0,\n",
       "  u'worldnews': 0.0})"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_base.predict(x_tr[5],theta_hand,labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see how good these weights are, by evaluating on the dev set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gtnlplib import evaluation\n",
    "reload(evaluation);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.394\n"
     ]
    }
   ],
   "source": [
    "# this applies your predict function to all the instances in ```x_dv```\n",
    "y_hat = clf_base.predict_all(x_dv,theta_hand,labels)\n",
    "print evaluation.acc(y_hat,y_dv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Deliverable 2.3**\n",
    "\n",
    "Now modify ```theta_hand``` in ```gtnlplib/hand_weights.py``` to get accuracy above 41%\n",
    "\n",
    "You can look at the training set to see how best to do this.\n",
    "\n",
    "(0.4 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from gtnlplib import hand_weights\n",
    "reload(evaluation)\n",
    "reload(hand_weights);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.46\n"
     ]
    }
   ],
   "source": [
    "# currently showing the accuracy for my weights\n",
    "y_hat = clf_base.predict_all(x_dv,hand_weights.theta_hand,labels)\n",
    "print evaluation.acc(y_hat,y_dv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# run this block to output predictions on the test set\n",
    "y_hat_te = clf_base.predict_all(x_te,hand_weights.theta_hand,labels)\n",
    "evaluation.write_predictions(y_hat_te,'hand-test.preds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Naive Bayes\n",
    "\n",
    "You'll now implement a Naive Bayes classifier, as described in chapter 1 of the notes.\n",
    "\n",
    "Total: 2 points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from gtnlplib import naive_bayes\n",
    "from gtnlplib import clf_base\n",
    "from gtnlplib import evaluation\n",
    "reload(naive_bayes);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Deliverable 3.1** (warmup) implement ```get_corpus_counts``` in ```naive_bayes.py```. This function should compute the word counts for a given label.\n",
    "\n",
    "(.2 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.0\n",
      "255.0\n"
     ]
    }
   ],
   "source": [
    "iama_counts = naive_bayes.get_corpus_counts(x_tr,y_tr,unicode('iama'));\n",
    "print iama_counts['four']\n",
    "print iama_counts['am']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Deliverable 3.2** Now implement ```estimate_pxy``` in ```naive_bayes.py```. This function should compute the *smoothed* multinomial distribution $\\log P(x \\mid y)$ for a given label $y$.\n",
    "\n",
    "Hint: note that this function takes the vocabulary as an argument. You have to assign a probability even for words that do not appear in documents with label $y$, if they are in the vocabulary.\n",
    "\n",
    "You can use ```get_corpus_counts``` in this function if you want to, but you don't have to.\n",
    "\n",
    "(.5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "log_pxy = naive_bayes.estimate_pxy(x_tr,y_tr,unicode('iama'),0.1,vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probabilities must sum to one!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0000000000000027"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(np.exp(log_pxy.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the log-probabilities of the words from the hand-tuned weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'todayilearned': 0.0, 'science': -8.5404041994449802, 'iama': 0.0, 'til': -11.412083824328992, 'worldnews': 0.0, 'askreddit': 0.0, '**OFFSET**': 0.0, 'ask': -7.7101941334790416, 'world': -7.3656964399724316, 'news': -8.8920858547297215}\n"
     ]
    }
   ],
   "source": [
    "print({word:log_pxy[word] for (_,word),weight in theta_hand.iteritems() if weight>0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Deliverable 3.3** Now you are ready to implement ```estimate_nb``` in ```naive_bayes.py```.\n",
    "\n",
    "- The goal is that the score given by ```clf_base.predict``` is equal to the joint probability $P(x,y)$, as described in the notes.\n",
    "- Don't forget the offset feature, whose weights should be set to the prior $\\log P(y)$.\n",
    "- The log-probabilities for the offset feature should not be smoothed.\n",
    "- You can call the functions you have defined above, but you don't have to.\n",
    "\n",
    "(0.8 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "theta_nb = naive_bayes.estimate_nb(x_tr,y_tr,0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(u'science',\n",
       " {u'askreddit': -1007.9847188388551,\n",
       "  u'iama': -975.84461062677087,\n",
       "  u'science': -949.40658879134503,\n",
       "  u'todayilearned': -976.5022264717561,\n",
       "  u'worldnews': -1004.6447250798954})"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_base.predict(x_tr[55],theta_nb,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(u'science',\n",
       " {u'askreddit': -1078.6362701511371,\n",
       "  u'iama': -1040.900147459866,\n",
       "  u'science': -976.34200102283455,\n",
       "  u'todayilearned': -983.32655052451423,\n",
       "  u'worldnews': -1029.2493890460514})"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_base.predict(x_dv[48],theta_nb,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.728\n"
     ]
    }
   ],
   "source": [
    "y_hat = clf_base.predict_all(x_dv,theta_nb,labels)\n",
    "print evaluation.acc(y_hat,y_dv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# execute this block to write predictions for the test set\n",
    "y_hat = clf_base.predict_all(x_te,theta_nb,labels)\n",
    "evaluation.write_predictions(y_hat,'nb-test.preds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_hat_te = evaluation.read_predictions('nb-test.preds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation.acc(y_hat_te,y_te)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Deliverable 3.4** Write a function in ```naive_bayes.py``` called ```find_best_smoother```, which finds the smoothing value that gives best performance on the dev data. \n",
    "\n",
    "Your function should trying at least the following values: [1e-3,1e-2,1e-1,1]. \n",
    "\n",
    "Then, using this smoothing value, run your Naive Bayes classifier on the test set, and output the results. (0.3 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "best_smoother, scores = naive_bayes.find_best_smoother(x_tr,y_tr,x_dv,y_dv,[1e-3,1e-2,1e-1,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's load the test data. Note that the ```y_te``` labels are all meaningless."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "theta_nb = naive_bayes.estimate_nb(x_tr,y_tr,best_smoother)\n",
    "y_hat = clf_base.predict_all(x_te,theta_nb,labels)\n",
    "evaluation.write_predictions(y_hat,'nb-best-test.preds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "y_hat = evaluation.read_predictions('nb-best-test.preds')\n",
    "print evaluation.acc(y_hat,y_te)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Deliverable 3.5** Run the code below to compare the learned weights using smoothing of $.001$ and $10.$\n",
    "\n",
    "Explain the resulting figure as best you can, in the text file ```text-answers.md```.\n",
    "\n",
    "(0.2 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "theta_nb_001 = naive_bayes.estimate_nb(x_tr,y_tr,.001)\n",
    "theta_nb_10 = naive_bayes.estimate_nb(x_tr,y_tr,10.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXEAAAFdCAYAAAD16V3pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nUsYMcUnKmCEuSRn7/154ZrcPzZp+AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x139fb358>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(theta_nb_001.values(),theta_nb_10.values());\n",
    "plt.axis('square');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Perceptron \n",
    "\n",
    "Total: 2 points\n",
    "\n",
    "The perceptron update is,\n",
    "\n",
    "\\begin{align}\n",
    "\\hat{y} = & \\text{argmax}_y \\theta^\\top f(x,y)\\\\\n",
    "\\theta \\gets & \\theta + f(x,y) - f(x,\\hat{y})\n",
    "\\end{align}\n",
    "\n",
    "You will now implement this classifier, using the file ```gtnlplib/perceptron.py```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'gtnlplib.perceptron' from 'gtnlplib\\perceptron.pyc'>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gtnlplib import perceptron\n",
    "reload(perceptron)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Deliverable 4.1 **\n",
    "\n",
    "Implement the perceptron *update*, $f(x,y) - f(x,\\hat{y})$, in the function ```perceptron_update``` in ```perceptron.py```. (0.5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "theta_perc = hand_weights.theta_hand_original.copy() #let's start with the hand-set weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-113-c2616431762b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[1;31m# no update when the prediction is correct\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mupdate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mperceptron\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mperceptron_update\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_tr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m110\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_tr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m110\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtheta_perc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32mC:\\Users\\Awba!\\gt-nlp-class\\psets\\ps1\\gtnlplib\\perceptron.pyc\u001b[0m in \u001b[0;36mperceptron_update\u001b[0;34m(x, y, weights, labels)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \"\"\"\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[1;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mupdate\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: "
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "# no update when the prediction is correct\n",
    "update = perceptron.perceptron_update(x_tr[110],y_tr[110],theta_perc,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# update when the prediction is incorrect\n",
    "i=20\n",
    "update =perceptron.perceptron_update(x_tr[i],y_tr[i],theta_perc,labels)\n",
    "print update.items()[:5]\n",
    "print len(update)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Deliverable 4b **\n",
    "\n",
    "Now implement the perceptron algorithm. Your implementation should take as inputs:\n",
    "\n",
    "- The training instances $x$\n",
    "- The training labels $y$\n",
    "- The number of iterations to train\n",
    "\n",
    "It should use your ```update``` function, and it should return:\n",
    "\n",
    "- weights $\\theta$\n",
    "- a list of the weights at each iteration\n",
    "\n",
    "Specifically, you should implement ```estimate_perceptron``` in ```perceptron.py``` (0.5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reload(perceptron);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "theta_perc,theta_perc_history = perceptron.estimate_perceptron(x_tr[:10],y_tr[:10],3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print theta_perc[('science','its')]\n",
    "print theta_perc[('science','what')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm including the running time (on my lenovo X1 carbon laptop) for reference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%timeit\n",
    "theta_perc,theta_perc_history = perceptron.estimate_perceptron(x_tr,y_tr,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "theta_perc,theta_perc_history = perceptron.estimate_perceptron(x_tr,y_tr,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# run this to plot the accuracy over iterations\n",
    "def plot_accs(weight_history,x_tr=x_tr,y_tr=y_tr,x_dv=x_dv,y_dv=y_dv):\n",
    "    tr_accs = []\n",
    "    dv_accs = []\n",
    "    for theta in weight_history:\n",
    "        tr_accs.append(evaluation.acc(clf_base.predict_all(x_tr,theta,labels),y_tr))\n",
    "        dv_accs.append(evaluation.acc(clf_base.predict_all(x_dv,theta,labels),y_dv))\n",
    "    plt.plot(tr_accs,'--')\n",
    "    plt.plot(dv_accs)\n",
    "    plt.xlabel('iteration')\n",
    "    plt.ylabel('accuracy');\n",
    "    plt.legend(['training','dev'],loc='lower right');\n",
    "    return tr_accs,dv_accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_hat = clf_base.predict_all(x_dv,theta_perc,labels)\n",
    "print evaluation.acc(y_hat,y_dv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_accs(theta_perc_history);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# execute this code to write the predictions on the dev and training data\n",
    "y_hat_dv = clf_base.predict_all(x_dv,theta_perc,labels)\n",
    "evaluation.write_predictions(y_hat_dv,'perc-dev.preds')\n",
    "y_hat_te = clf_base.predict_all(x_te,theta_perc,labels)\n",
    "evaluation.write_predictions(y_hat_te,'perc-test.preds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Averaged Perceptron \n",
    "\n",
    "You will now implement the averaged perceptron, which often achieves better generalization than the standard perceptron. The basic idea, as described in the notes, is to average the weights across each update:\n",
    "\n",
    "\\begin{align}\n",
    "\\hat{y} \\gets & \\text{argmax}_y \\theta^{\\top}f(x,y)\\\\\n",
    "\\theta_t \\gets & f(x,y) - f(x,\\hat{y})\\\\\n",
    "m \\gets & m + \\theta_t\\\\\n",
    "\\overline{\\theta} \\gets & \\frac{m}{t}\n",
    "\\end{align}\n",
    "\n",
    "Note that during training, prediction is performed using the non-averaged weights, $\\theta$. The averaged weights are only returned at the end. They often give better generalization than the standard perceptron.\n",
    "\n",
    "However, it is too inefficient to repeatedly compute the sum $m + \\theta_t$. The reason is that we must perform an operation for every feature with non-zero weight. There are many more such features than there are non-zero features in any given example, $f(x_i, y)$. Therefore, this addition will dominate the computation.\n",
    "\n",
    "An efficient solution was pointed out by [Daume 2006](http://hal3.name/docs/daume06thesis.pdf). \n",
    "Let $\\delta_t$ indicate the update at time $t$.\n",
    "Assuming $\\theta^0 = 0$, \n",
    "\\begin{align*}\n",
    "\\theta^t = & \\theta^{t-1} + \\delta_t \\\\\n",
    "= & \\sum_{t' < t} \\delta_{t'}\n",
    "\\end{align*}\n",
    "\n",
    "We would like to compute the sum of the weight vectors,\n",
    "\\begin{align*}\n",
    "\\sum_t^T \\theta_t = & \\sum_t^T \\sum_{t' \\leq t} \\delta_{t'} = T \\delta_0 + (T-1) \\delta_1 + (T - 2) \\delta_2 + \\ldots + \\delta_T \\\\ \n",
    "= & \\sum_t^T (T - t) \\delta_t\\\\\n",
    "= & T \\sum_t^T \\delta_t - \\sum_t^T t \\delta_t \\\\\n",
    "= & T \\theta_t - \\sum_t^T t \\delta_t \\\\\n",
    "\\frac{1}{T} \\sum_t^T \\theta_t = & \\theta_T - \\frac{1}{T} \\sum_t^T t \\delta_t\n",
    "\\end{align*}\n",
    "\n",
    "This means we need to keep another running sum, $\\sum_t^T t \\delta_t$, the sum of scaled updates. \n",
    "To compute the average, we divide by the number of updates $T$ and subtract it from the current weight vector.\n",
    "\n",
    "**Deliverable 4.3**\n",
    "\n",
    "Implement ```estimate_average_perceptron``` in ```perceptron.py```. (1 point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reload(perceptron);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "theta_avp,theta_avp_history = perceptron.estimate_avg_perceptron(x_tr[:10],y_tr[:10],3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%timeit\n",
    "theta_avp,theta_avp_history = perceptron.estimate_avg_perceptron(x_tr,y_tr,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "theta_avp,theta_avp_history = perceptron.estimate_avg_perceptron(x_tr,y_tr,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_hat = clf_base.predict_all(x_dv,theta_avp,labels)\n",
    "print evaluation.acc(y_hat,y_dv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_accs(theta_avp_history);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# execute this code to write the predictions on the dev and training data\n",
    "y_hat_dv = clf_base.predict_all(x_dv,theta_avp,labels)\n",
    "evaluation.write_predictions(y_hat_dv,'avp-dev.preds')\n",
    "y_hat_te = clf_base.predict_all(x_te,theta_avp,labels)\n",
    "evaluation.write_predictions(y_hat_te,'avp-test.preds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "evaluation.acc(y_hat_te,y_te)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Logistic regression\n",
    "\n",
    "Total: 2 points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Deliverable 5.1** Write a function to compute the conditional probability,\n",
    "\\begin{equation}\n",
    "p(y \\mid x; \\theta) = \\frac{\\exp(\\theta^{\\top} f(x,y))}{\\sum_{y'}\\exp(\\theta^{\\top} f(x,y'))}\n",
    "\\end{equation}\n",
    "\n",
    "Implement this in ```compute_py``` in ```logreg.py```. You should use your ```predict``` function from ```clf_base.py```.\n",
    "\n",
    "(0.5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from gtnlplib import logreg\n",
    "reload(logreg);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logreg.compute_py({'i':1,'am':2},theta_hand,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logreg.compute_py({'i':1,'news':2,'science':1},theta_hand,labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Deliverable 5.2** Complete the function ```estimate_logreg``` in ```logreg.py```. (1 point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# train on the first ten instances\n",
    "theta_lr,theta_lr_hist = logreg.estimate_logreg(x_tr[:10],y_tr[:10],3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# this takes approximately 2 minutes to execute on my laptop\n",
    "theta_lr,theta_lr_hist = logreg.estimate_logreg(x_tr,y_tr,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_hat = clf_base.predict_all(x_dv,theta_lr,labels)\n",
    "evaluation.write_predictions(y_hat,'lr-dev.preds')\n",
    "print evaluation.acc(y_hat,y_dv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_hat_te = clf_base.predict_all(x_te,theta_lr,labels)\n",
    "evaluation.write_predictions(y_hat_te,'lr-test.preds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print evaluation.acc(y_hat_te,y_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_accs(theta_lr_hist);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The figure suggests that you can get higher accuracy by training for longer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Deliverable 5.3** \n",
    "\n",
    "\n",
    "- Try to improve on the performance that you get with the default hyperparameters.\n",
    "- Specifically, try different values for regularization, learning rate, and number of iterations\n",
    "- Because training is somewhat slow, you will have to be careful in how you do this.\n",
    "- Write the predictions of your best models to ```lr-best-dev.preds``` and ```lr-best-test.preds```.\n",
    "- You should be able to get at least 66% accuracy on the dev set.\n",
    "- As you try different configurations **save the weights** for each configuration separately. This will help you with problem 6.2.\n",
    "\n",
    "(0.5 points)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "theta_lr_best,theta_lr_hist_best = logreg.estimate_logreg(x_tr,y_tr,20) #add your hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_accs(theta_lr_best);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "theta_lr_best,theta_lr_hist_best = logreg.estimate_logreg(x_tr,y_tr,...)#add your hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_hat = clf_base.predict_all(x_dv,theta_lr_best,labels)\n",
    "evaluation.write_predictions(y_hat,'lr-best-dev.preds')\n",
    "y_hat_te = clf_base.predict_all(x_te,theta_lr_best,labels)\n",
    "evaluation.write_predictions(y_hat_te,'lr-best-test.preds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# here are the scores for some weights that i got\n",
    "y_hat_dv = evaluation.read_predictions('lr-best-dev.preds')\n",
    "print evaluation.acc(y_hat_dv,y_dv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_hat_te = evaluation.read_predictions('lr-best-test.preds')\n",
    "print evaluation.acc(y_hat_te,y_te)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Feature analysis\n",
    "\n",
    "1 points for 4650; 0.5 point for 7650\n",
    "\n",
    "** Deliverable 6.1**\n",
    "\n",
    "Implement ```get_top_features_for_label``` in ```clf_base.py```. (0.5 points for 4650 / .25 points for 7650)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reload(clf_base);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf_base.get_top_features_for_label(theta_lr_best,'science',5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf_base.get_top_features_for_label(theta_lr_best,'worldnews',5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Deliverable 6.2**\n",
    "\n",
    "- Now compare the top 5 features and weights for logistic regression under the largest regularizer and smallest regularizer that you tried in problem 5.3. \n",
    "- Paste the output into ```text_answers.md```, and explain the difference.\n",
    "- You cannot get full credit if your logistic regression classifier is not implemented correctly, so make sure you pass the units tests for part 5 before starting this.\n",
    "- 0.5 points for 4650 / 0.25 points for 7650. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# use this cell (and make more cells) to run your code to get the top features.\n",
    "# save the output in the notebook for when you submit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Better preprocessing\n",
    "\n",
    "Total: 1 points for CS 4650; 0.5 points for CS 7650.\n",
    "\n",
    "Now try to make some changes to the preprocessing code to improve the performance of these classifiers.\n",
    "\n",
    "**Deliverable 7.1** \n",
    "\n",
    "- Write the function ```custom_preproc``` in ```preproc.py```\n",
    "- Then load the data using the code below\n",
    "- Choose one of the classifiers, train it on this new data, and print out the predictions on the test set and dev, using the code block below that.\n",
    "\n",
    "Full credit for doing something interesting, +1 points for beating my best test set score. (0.75 point for 4650 / 0.25 points for 7650)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reload(preproc);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_tr_bake,x_tr_bake = preproc.read_data('reddit-train.csv', #filename\n",
    "                                    'subreddit', #label field\n",
    "                                    preprocessor=preproc.custom_preproc) #your preprocessor\n",
    "y_dv_bake,x_dv_bake = preproc.read_data('reddit-dev.csv', #filename\n",
    "                                    'subreddit', #label field\n",
    "                                    preprocessor=preproc.custom_preproc) #your preprocessor\n",
    "y_te_bake,x_te_bake = preproc.read_data('reddit-test.csv', #filename\n",
    "                                    'subreddit', #label field\n",
    "                                    preprocessor=preproc.custom_preproc) #your preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# use this block to train your classifier on the new data.\n",
    "# you don't have to use Naive Bayes!\n",
    "theta_nb = naive_bayes.estimate_nb(x_tr_bake,y_tr_bake,smoothing=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_hat_dv_bake = clf_base.predict_all(x_dv_bake,theta_nb,labels)\n",
    "evaluation.write_predictions(y_hat_dv_bake,'bakeoff-dev.preds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Here's how well my preprocessed features do on the dev set\n",
    "evaluation.acc(y_hat_dv_bake,y_dv_bake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_hat_te_bake = clf_base.predict_all(x_te_bake,theta_nb,labels)\n",
    "evaluation.write_predictions(y_hat_te_bake,'bakeoff-test.preds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Here's how well my preprocessed features do on the test set\n",
    "evaluation.acc(y_hat_te_bake,y_te_bake)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Deliverable 7.2 **\n",
    "\n",
    "Explain your novel preprocessing code in ```text-answers.md```\n",
    "\n",
    "(0.25 points for 4650, 0.25 points for 7650)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. 7650 Research Question\n",
    "\n",
    "(1 point.) CS 4650 students may do this component if they want; if they do, then the assignment will be graded as if they are in 7650. This is optional for CS4650 students, but if you submit something for this part, that is how you will be scored -- we're not taking the max over the two possible scoring options. CS 7650 students must do this part.\n",
    "\n",
    "You will select a recent research paper that performs *document* classification, using text. Summarize the paper, answering the following questions:\n",
    "\n",
    "- What are the labels, and how were they obtained?\n",
    "- Why is it interesting/useful to predict these labels?  \n",
    "- What classifier(s) do they use, and the reasons behind their choice? Do they use linear classifiers like the ones in this problem set?\n",
    "- What features do they use? Explain any features outside the bag-of-words model, and why they used them.\n",
    "- What is the conclusion of the paper? Do they compare between classifiers, between feature sets, or on some other dimension? \n",
    "- Give a one-sentence summary of the message that they are trying to leave for the reader.\n",
    "\n",
    "Your selection of papers is determined by the last digit of your GTID.\n",
    "\n",
    "- Digits 0,1: choose from ACL 2016, AAAI 2016\n",
    "- Digits 2,3,4: choose from NAACL 2016, KDD 2016\n",
    "- Digits 5,6,7: choose from EMNLP 2016, ICWSM 2016\n",
    "- Digits 8,9: choose from ACL 2015, IJCAI 2016\n",
    "\n",
    "You must choose a paper in the main conference (not workshops). The paper must be at least four pages long. All papers from these conferences are available for free online."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}